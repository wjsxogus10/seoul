import streamlit as st
import pandas as pd
import geopandas as gpd
import plotly.express as px
import os
from shapely.geometry import Point

# --------------------------------------------------------------------------
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="ì„œìš¸ì‹œ ë„ì‹œê³„íš ëŒ€ì‹œë³´ë“œ")
st.title("ğŸ™ï¸ ì„œìš¸ì‹œ ë„ì‹œê³„íš ë° ëŒ€ì¤‘êµí†µ ê°œì„  ëŒ€ì‹œë³´ë“œ")

# --------------------------------------------------------------------------
# ìœ í‹¸ í•¨ìˆ˜: ì•ˆì „í•œ íŒŒì¼ ì½ê¸° (utf-8 -> cp949 fallback)
# --------------------------------------------------------------------------
def safe_read_csv(path):
    try:
        return pd.read_csv(path, encoding='utf-8')
    except Exception:
        try:
            return pd.read_csv(path, encoding='cp949')
        except Exception:
            return None

def safe_read_excel(path):
    try:
        return pd.read_excel(path)
    except Exception:
        return None

# --------------------------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ ë° ë³‘í•© í•¨ìˆ˜ (Robust + Defensive)
# --------------------------------------------------------------------------
@st.cache_data(show_spinner="ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
def load_and_merge_data():
    # --- 1) ê¸°ë³¸ ì§€ë„(GeoJSON) ë¡œë“œ ---
    map_url = "https://raw.githubusercontent.com/southkorea/seoul-maps/master/kostat/2013/json/seoul_municipalities_geo_simple.json"
    try:
        gdf = gpd.read_file(map_url)
        gdf = gdf.to_crs(epsg=4326)
    except Exception as e:
        # ì§€ë„ ë¡œë“œ ì‹¤íŒ¨
        return None, None

    # ìì¹˜êµ¬ëª… ë³´ì •
    if 'name' in gdf.columns:
        gdf['ìì¹˜êµ¬ëª…'] = gdf['name']
    elif 'SIG_KOR_NM' in gdf.columns:
        gdf['ìì¹˜êµ¬ëª…'] = gdf['SIG_KOR_NM']
    else:
        # ì¹˜ëª…ì : ìì¹˜êµ¬ëª… ì—†ìœ¼ë©´ ì¤‘ë‹¨
        return None, None

    # ë©´ì  ê³„ì‚° (km^2) â€” íˆ¬ì˜ í›„ ë©´ì 
    try:
        gdf['ë©´ì (kmÂ²)'] = gdf.geometry.to_crs(epsg=5179).area / 1_000_000
    except Exception:
        gdf['ë©´ì (kmÂ²)'] = None

    # --- 2) ê¸°ë³¸ ì»¬ëŸ¼ ì´ˆê¸°í™”(ë°©ì–´ì ) ---
    desired_cols = [
        'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜', 'ì¸êµ¬ ë°€ë„', 'ì§‘ê°ì‹œì„¤ ìˆ˜',
        'ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜', 'ë²„ìŠ¤ì •ë¥˜ì¥ ë°€ë„',
        'ì§€í•˜ì² ì—­_ìˆ˜', 'ì§€í•˜ì² ì—­ ë°€ë„',
        'ì´_êµí†µìˆ˜ë‹¨_ìˆ˜', 'ëŒ€ì¤‘êµí†µ ë°€ë„',
        'ì¸êµ¬ ëŒ€ë¹„ êµí†µìˆ˜ë‹¨ ë¹„ìœ¨', 'êµí†µ ë¶€ì¡± ìˆœìœ„'
    ]
    for c in desired_cols:
        if c not in gdf.columns:
            gdf[c] = 0

    # --- 3) ìƒì£¼ ì¸êµ¬ ë³‘í•©(íŒŒì¼ëª… ê°€ì •) ---
    pop_path = './data/ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤(ìƒì£¼ì¸êµ¬-ìì¹˜êµ¬).csv'
    if os.path.exists(pop_path):
        try:
            df_pop = safe_read_csv(pop_path)
            if df_pop is not None:
                gu_col = next((c for c in df_pop.columns if 'ìì¹˜êµ¬' in c), None)
                pop_col = next((c for c in df_pop.columns if 'ìƒì£¼ì¸êµ¬' in c or 'ì´_ìƒì£¼ì¸êµ¬' in c), None)
                if gu_col and pop_col:
                    grp = df_pop.groupby(gu_col)[pop_col].mean().reset_index()
                    grp = grp.rename(columns={gu_col:'ìì¹˜êµ¬ëª…', pop_col:'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'})
                    gdf = gdf.merge(grp, on='ìì¹˜êµ¬ëª…', how='left')
                    gdf['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'] = gdf['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'].fillna(0)
                    # ì¸êµ¬ ë°€ë„ ê³„ì‚° (ë©´ì  0 ë°©ì§€)
                    gdf['ì¸êµ¬ ë°€ë„'] = gdf.apply(lambda r: r['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'] / r['ë©´ì (kmÂ²)'] if r['ë©´ì (kmÂ²)'] and r['ë©´ì (kmÂ²)']>0 else 0, axis=1)
        except Exception:
            pass

    # --- 4) ì§‘ê°ì‹œì„¤ ìˆ˜ ë³‘í•© ---
    biz_path = './data/ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤(ì§‘ê°ì‹œì„¤-ìì¹˜êµ¬).csv'
    if os.path.exists(biz_path):
        try:
            df_biz = safe_read_csv(biz_path)
            if df_biz is not None:
                biz_count_col = next((c for c in df_biz.columns if 'ì§‘ê°ì‹œì„¤' in c or 'ì‹œì„¤ìˆ˜' in c or 'ì§‘ê°' in c), None)
                gu_col_biz = next((c for c in df_biz.columns if 'ìì¹˜êµ¬' in c), None)
                if biz_count_col and gu_col_biz:
                    grp = df_biz.groupby(gu_col_biz)[biz_count_col].mean().reset_index()
                    grp = grp.rename(columns={gu_col_biz:'ìì¹˜êµ¬ëª…', biz_count_col:'ì§‘ê°ì‹œì„¤ ìˆ˜'})
                    gdf = gdf.merge(grp, on='ìì¹˜êµ¬ëª…', how='left')
                    gdf['ì§‘ê°ì‹œì„¤ ìˆ˜'] = gdf['ì§‘ê°ì‹œì„¤ ìˆ˜'].fillna(0)
        except Exception:
            pass

    # --- 5) ì§€í•˜ì²  ë°ì´í„° ë³‘í•© (ìœ ì—° ì²˜ë¦¬) ---
    subway_path = './data/ì§€í•˜ì²  ìœ„ê²½ë„.CSV'
    subway_count_from_file = None
    if os.path.exists(subway_path):
        try:
            df_sub = safe_read_csv(subway_path)
            if df_sub is not None:
                # ê°€ëŠ¥ì„± ìˆëŠ” ìœ„ê²½ë„/ìì¹˜êµ¬/ê°œìˆ˜ ì»¬ëŸ¼ ìë™ íƒì§€
                lon_candidates = ['point_x', 'X', 'ê²½ë„', 'lon', 'longitude']
                lat_candidates = ['point_y', 'Y', 'ìœ„ë„', 'lat', 'latitude']
                gu_candidates = ['ìì¹˜êµ¬', 'ìì¹˜êµ¬_ì½”ë“œ_ëª…', 'ìì¹˜êµ¬ëª…', 'ìì¹˜êµ¬ëª….1', 'gu', 'êµ¬']

                lon_col = next((c for c in df_sub.columns if c in lon_candidates), None)
                lat_col = next((c for c in df_sub.columns if c in lat_candidates), None)
                gu_col_sub = next((c for c in df_sub.columns if any(k in c for k in gu_candidates)), None)
                count_col = next((c for c in df_sub.columns if 'ì§€í•˜ì² ì—­_ìˆ˜' in c or 'ì§€í•˜ì² ì—­ìˆ˜' in c or 'ì§€í•˜ì² ì—­' in c and 'ë°€ë„' not in c), None)

                # ì»¬ëŸ¼ëª… í‘œì¤€í™”
                if gu_col_sub:
                    df_sub = df_sub.rename(columns={gu_col_sub: 'ìì¹˜êµ¬ëª…'})
                if count_col:
                    df_sub = df_sub.rename(columns={count_col: 'ì§€í•˜ì² ì—­_ìˆ˜'})

                # (A) ìœ„ê²½ë„ ì •ë³´ê°€ ìˆìœ¼ë©´ ê³µê°„ì¡°ì¸ìœ¼ë¡œ ì§‘ê³„
                if lon_col and lat_col:
                    df_sub = df_sub.dropna(subset=[lon_col, lat_col])
                    try:
                        geom = [Point(xy) for xy in zip(df_sub[lon_col].astype(float), df_sub[lat_col].astype(float))]
                        gdf_sub = gpd.GeoDataFrame(df_sub, geometry=geom, crs="EPSG:4326")
                        # ê³µê°„ì¡°ì¸ (points within polygons)
                        joined = gpd.sjoin(gdf_sub, gdf[['ìì¹˜êµ¬ëª…', 'geometry']], how='left', predicate='within')
                        cnt = joined.groupby('ìì¹˜êµ¬ëª…').size().reset_index(name='ì§€í•˜ì² ì—­_ìˆ˜')
                        subway_count_from_file = cnt
                    except Exception:
                        subway_count_from_file = None

                # (B) ì¢Œí‘œ ì—†ì§€ë§Œ íŒŒì¼ì— ì´ë¯¸ ì§‘ê³„ëœ 'ìì¹˜êµ¬ë³„ ì§€í•˜ì² ì—­ ìˆ˜'ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
                if subway_count_from_file is None and 'ìì¹˜êµ¬ëª…' in df_sub.columns and 'ì§€í•˜ì² ì—­_ìˆ˜' in df_sub.columns:
                    cnt = df_sub.groupby('ìì¹˜êµ¬ëª…')['ì§€í•˜ì² ì—­_ìˆ˜'].sum().reset_index()
                    subway_count_from_file = cnt

        except Exception:
            subway_count_from_file = None

    # merge subway counts if available
    if subway_count_from_file is not None:
        try:
            subway_count_from_file['ìì¹˜êµ¬ëª…'] = subway_count_from_file['ìì¹˜êµ¬ëª…'].astype(str)
            gdf['ìì¹˜êµ¬ëª…'] = gdf['ìì¹˜êµ¬ëª…'].astype(str)
            gdf = gdf.merge(subway_count_from_file, on='ìì¹˜êµ¬ëª…', how='left')
            gdf['ì§€í•˜ì² ì—­_ìˆ˜'] = gdf['ì§€í•˜ì² ì—­_ìˆ˜'].fillna(0)
        except Exception:
            gdf['ì§€í•˜ì² ì—­_ìˆ˜'] = gdf.get('ì§€í•˜ì² ì—­_ìˆ˜', 0).fillna(0)

    # --- 6) ë²„ìŠ¤ ì •ë¥˜ì¥ ë°ì´í„° ë³‘í•© (ìœ ì—° ì²˜ë¦¬) ---
    bus_paths = ['./data/GGD_StationInfo_M.xlsx', './data/ë²„ìŠ¤ì •ë¥˜ì¥.xlsx', './data/ë²„ìŠ¤ì •ë¥˜ì¥.csv']
    bus_count_from_file = None
    for p in bus_paths:
        if os.path.exists(p):
            try:
                if p.endswith('.xlsx') or p.endswith('.xls'):
                    df_bus = safe_read_excel(p)
                else:
                    df_bus = safe_read_csv(p)
                if df_bus is None:
                    continue

                lon_candidates = ['X', 'lon', 'ê²½ë„', 'longitude', 'point_x']
                lat_candidates = ['Y', 'lat', 'ìœ„ë„', 'latitude', 'point_y']
                lon_col = next((c for c in df_bus.columns if c in lon_candidates), None)
                lat_col = next((c for c in df_bus.columns if c in lat_candidates), None)
                gu_col_bus = next((c for c in df_bus.columns if 'ìì¹˜êµ¬' in c or 'êµ¬' == c), None)
                count_col = next((c for c in df_bus.columns if 'ì •ë¥˜ì¥' in c or 'ë²„ìŠ¤' in c and 'ìˆ˜' in c), None)

                if lon_col and lat_col:
                    df_bus = df_bus.dropna(subset=[lon_col, lat_col])
                    geom = [Point(xy) for xy in zip(df_bus[lon_col].astype(float), df_bus[lat_col].astype(float))]
                    gdf_bus = gpd.GeoDataFrame(df_bus, geometry=geom, crs="EPSG:4326")
                    joined = gpd.sjoin(gdf_bus, gdf[['ìì¹˜êµ¬ëª…', 'geometry']], how='left', predicate='within')
                    cnt = joined.groupby('ìì¹˜êµ¬ëª…').size().reset_index(name='ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜')
                    bus_count_from_file = cnt
                elif gu_col_bus and count_col:
                    cnt = df_bus.groupby(gu_col_bus)[count_col].sum().reset_index()
                    cnt = cnt.rename(columns={gu_col_bus:'ìì¹˜êµ¬ëª…', count_col:'ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜'})
                    bus_count_from_file = cnt

                if bus_count_from_file is not None:
                    break
            except Exception:
                continue

    # merge bus counts if available
    if bus_count_from_file is not None:
        try:
            bus_count_from_file['ìì¹˜êµ¬ëª…'] = bus_count_from_file['ìì¹˜êµ¬ëª…'].astype(str)
            gdf['ìì¹˜êµ¬ëª…'] = gdf['ìì¹˜êµ¬ëª…'].astype(str)
            gdf = gdf.merge(bus_count_from_file, on='ìì¹˜êµ¬ëª…', how='left')
            gdf['ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜'] = gdf['ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜'].fillna(0)
        except Exception:
            gdf['ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜'] = gdf.get('ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜', 0).fillna(0)
    else:
        gdf['ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜'] = gdf.get('ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜', 0).fillna(0)

    # --- 7) ì§€í•˜ì² /ë²„ìŠ¤ ë°€ë„ ê³„ì‚°(ë©´ì  0 ì²´í¬) ---
    def safe_density(count, area):
        try:
            return count / area if area and area > 0 else 0
        except Exception:
            return 0

    gdf['ë²„ìŠ¤ì •ë¥˜ì¥ ë°€ë„'] = gdf.apply(lambda r: safe_density(r.get('ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜', 0), r.get('ë©´ì (kmÂ²)', 0)), axis=1)
    gdf['ì§€í•˜ì² ì—­ ë°€ë„'] = gdf.apply(lambda r: safe_density(r.get('ì§€í•˜ì² ì—­_ìˆ˜', 0), r.get('ë©´ì (kmÂ²)', 0)), axis=1)

    # --- 8) ì´ êµí†µìˆ˜ë‹¨ / ëŒ€ì¤‘êµí†µ ë°€ë„ / ì¸êµ¬ ëŒ€ë¹„ ë¹„ìœ¨ / ë¶€ì¡± ìˆœìœ„ ---
    # ë°©ì–´: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ì— ê¸°ë³¸ê°’ ì„¤ì •
    for c in ['ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜', 'ì§€í•˜ì² ì—­_ìˆ˜', 'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜']:
        if c not in gdf.columns:
            gdf[c] = 0
    gdf['ì´_êµí†µìˆ˜ë‹¨_ìˆ˜'] = gdf['ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜'].fillna(0) + gdf['ì§€í•˜ì² ì—­_ìˆ˜'].fillna(0)
    gdf['ëŒ€ì¤‘êµí†µ ë°€ë„'] = gdf.apply(lambda r: safe_density(r['ì´_êµí†µìˆ˜ë‹¨_ìˆ˜'], r.get('ë©´ì (kmÂ²)', 0)), axis=1)

    population_safe = gdf['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'].replace(0, pd.NA)
    # ì¸êµ¬ê°€ 0ì´ë©´ ë¶„ëª¨ë¥¼ 1ë¡œ ì¹˜í™˜í•˜ì—¬ ë¬´í•œëŒ€/NaN ë°©ì§€
    gdf['ì¸êµ¬ ëŒ€ë¹„ êµí†µìˆ˜ë‹¨ ë¹„ìœ¨'] = gdf.apply(lambda r: r['ì´_êµí†µìˆ˜ë‹¨_ìˆ˜'] / (r['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'] if r['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'] and r['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜']>0 else 1), axis=1)
    gdf['êµí†µ ë¶€ì¡± ìˆœìœ„'] = gdf['ì¸êµ¬ ëŒ€ë¹„ êµí†µìˆ˜ë‹¨ ë¹„ìœ¨'].rank(ascending=True, method='min')

    # ì¼ë¶€ ì»¬ëŸ¼ íƒ€ì… ì •ë¦¬ (ìˆ«ìí˜•)
    num_cols = ['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜', 'ì¸êµ¬ ë°€ë„', 'ì§‘ê°ì‹œì„¤ ìˆ˜',
                'ë²„ìŠ¤ì •ë¥˜ì¥_ìˆ˜', 'ë²„ìŠ¤ì •ë¥˜ì¥ ë°€ë„',
                'ì§€í•˜ì² ì—­_ìˆ˜', 'ì§€í•˜ì² ì—­ ë°€ë„',
                'ì´_êµí†µìˆ˜ë‹¨_ìˆ˜', 'ëŒ€ì¤‘êµí†µ ë°€ë„', 'ì¸êµ¬ ëŒ€ë¹„ êµí†µìˆ˜ë‹¨ ë¹„ìœ¨', 'êµí†µ ë¶€ì¡± ìˆœìœ„']
    for c in num_cols:
        try:
            gdf[c] = pd.to_numeric(gdf[c], errors='coerce').fillna(0)
        except Exception:
            pass

    # ë¹ˆ stations DataFrame (í•„ìš”í•˜ë©´ ë¦¬í„´ì— í¬í•¨)
    df_stations = pd.DataFrame()
    return gdf, df_stations

# --------------------------------------------------------------------------
# 3. í™”ë©´ êµ¬ì„± ë° ì‹œê°í™”
# --------------------------------------------------------------------------
result = load_and_merge_data()
if result is None or result[0] is None:
    st.error("âŒ GeoJSON ì§€ë„ ë¡œë“œ ë˜ëŠ” í•„ìˆ˜ ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ë„¤íŠ¸ì›Œí¬/íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”)")
    st.stop()

gdf, df_stations = result

st.sidebar.header("ğŸ” ë¶„ì„ ì˜µì…˜")

# ì§€í‘œ ì„¤ì • (í‘œì‹œë  ì´ë¦„ : ì»¬ëŸ¼ëª…)
metrics_order = [
    ('ìƒì£¼ ì¸êµ¬', 'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜'),
    ('ì¸êµ¬ ë°€ë„', 'ì¸êµ¬ ë°€ë„'),
    ('ì§‘ê°ì‹œì„¤ ìˆ˜', 'ì§‘ê°ì‹œì„¤ ìˆ˜'),
    ('ë²„ìŠ¤ì •ë¥˜ì¥ ë°€ë„', 'ë²„ìŠ¤ì •ë¥˜ì¥ ë°€ë„'),
    ('ì§€í•˜ì² ì—­ ë°€ë„', 'ì§€í•˜ì² ì—­ ë°€ë„'),
    ('ëŒ€ì¤‘êµí†µ ë°€ë„ (ë²„ìŠ¤+ì§€í•˜ì² )', 'ëŒ€ì¤‘êµí†µ ë°€ë„'),
    ('êµí†µ ë¶€ì¡± ìˆœìœ„ (ì¸êµ¬ ëŒ€ë¹„)', 'êµí†µ ë¶€ì¡± ìˆœìœ„')
]

valid_metrics = {}
for k, v in metrics_order:
    if v in gdf.columns:
        # ìˆœìœ„ëŠ” ê°’ì´ 0ì´ì–´ë„ ì˜ë¯¸ê°€ ìˆìœ¼ë¯€ë¡œ í¬í•¨
        if gdf[v].sum() > 0 or 'ìˆœìœ„' in k:
            valid_metrics[k] = v

if not valid_metrics:
    st.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# 1) ì§€í‘œ ì„ íƒ
selected_name = st.sidebar.radio("ë¶„ì„í•  ì§€í‘œ ì„ íƒ", list(valid_metrics.keys()))
selected_col = valid_metrics[selected_name]

st.sidebar.markdown("---")
# 2) ê°œìˆ˜ ì¡°ì ˆ
display_count = st.sidebar.slider("ğŸ“Š ê·¸ë˜í”„/í‘œ í‘œì‹œ ê°œìˆ˜", 5, 25, 10)
st.sidebar.markdown("---")
# 3) ìì¹˜êµ¬ ì„ íƒ
district_list = ['ì „ì²´ ì„œìš¸ì‹œ'] + sorted(gdf['ìì¹˜êµ¬ëª…'].astype(str).unique().tolist())
selected_district = st.sidebar.selectbox("ìì¹˜êµ¬ ìƒì„¸ ë³´ê¸°", district_list)

# ìƒ‰ìƒìŠ¤ì¼€ì¼
colorscale = 'Blues' if selected_col in ['ì´_ìƒì£¼ì¸êµ¬_ìˆ˜', 'ì¸êµ¬ ë°€ë„', 'ì§‘ê°ì‹œì„¤ ìˆ˜'] else 'Reds'

# ë ˆì´ì•„ì›ƒ: ì§€ë„ + ê·¸ë˜í”„
col_map, col_chart = st.columns([1, 1])

with col_map:
    st.subheader(f"ğŸ—ºï¸ ì„œìš¸ì‹œ {selected_name} ì§€ë„")

    center_lat, center_lon, zoom = 37.5665, 126.9780, 9.5
    map_data = gdf.copy()

    if selected_district != 'ì „ì²´ ì„œìš¸ì‹œ':
        map_data = gdf[gdf['ìì¹˜êµ¬ëª…'] == selected_district]
        # centroid ê³„ì‚° ì•ˆì „ì„±
        try:
            center_lat = float(map_data.geometry.centroid.y.values[0])
            center_lon = float(map_data.geometry.centroid.x.values[0])
            zoom = 11.0
        except Exception:
            center_lat, center_lon, zoom = 37.5665, 126.9780, 9.5

    # plotly choropleth_mapbox ì‚¬ìš©
    try:
        fig = px.choropleth_mapbox(
            map_data,
            geojson=map_data.geometry.__geo_interface__,
            locations=map_data.index,
            color=selected_col,
            mapbox_style="carto-positron",
            zoom=zoom,
            center={"lat": center_lat, "lon": center_lon},
            opacity=0.7,
            hover_name='ìì¹˜êµ¬ëª…',
            hover_data=[selected_col],
            color_continuous_scale=colorscale
        )
        fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0}, height=500)
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error("ì§€ë„ë¥¼ ê·¸ë¦¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.exception(e)

with col_chart:
    st.subheader(f"ğŸ“Š {selected_name} ìˆœìœ„ ë¹„êµ")
    sort_opt = st.radio("ì •ë ¬ ê¸°ì¤€:", ["ìƒìœ„", "í•˜ìœ„"], horizontal=True, key="sort_chart")
    ascending = False if sort_opt == "ìƒìœ„" else True
    df_sorted = gdf.sort_values(by=selected_col, ascending=ascending).head(display_count).copy()

    # ê°•ì¡° ìƒ‰ìƒ
    df_sorted['__color__'] = df_sorted['ìì¹˜êµ¬ëª…'].apply(lambda x: '#FF4B4B' if x == selected_district else '#8884d8')

    fig_bar = px.bar(df_sorted, x='ìì¹˜êµ¬ëª…', y=selected_col, text=selected_col, color='__color__', color_discrete_map='identity')
    fmt = '%{text:.0f}' if 'ìˆœìœ„' in selected_name or 'ì¸êµ¬' in selected_name else '%{text:.4f}'
    fig_bar.update_traces(texttemplate=fmt, textposition='outside')
    fig_bar.update_layout(showlegend=False, xaxis_title=None, height=500, margin={"r":0,"t":20,"l":0,"b":0})
    st.plotly_chart(fig_bar, use_container_width=True)

# í•˜ë‹¨: í…Œì´ë¸” ë° ë‹¤ìš´ë¡œë“œ
st.markdown("---")
st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„° í‘œ")

# í‘œì‹œí•  ì»¬ëŸ¼ ëª©ë¡ ìƒì„± (ìì¹˜êµ¬ëª… + ì„ íƒëœ ì§€í‘œë“¤)
cols_to_show = ['ìì¹˜êµ¬ëª…'] + list(valid_metrics.values())
# ì¤‘ë³µ ì œê±°
cols_to_show = list(dict.fromkeys(cols_to_show))
# ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
cols_to_show = [c for c in cols_to_show if c in gdf.columns]

df_table = gdf[cols_to_show].sort_values(by=selected_col, ascending=(sort_opt=="í•˜ìœ„")).head(display_count)
st.dataframe(df_table, use_container_width=True, hide_index=True)

csv = gdf[cols_to_show].to_csv(index=False).encode('utf-8-sig')
st.download_button("ğŸ“¥ ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)", csv, "seoul_analysis.csv", "text/csv")

st.markdown("#### âš™ï¸ ì°¸ê³ ")
st.markdown("- ë°ì´í„° íŒŒì¼ì€ `./data/` í´ë”ì— ìœ„ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: `ì§€í•˜ì²  ìœ„ê²½ë„.CSV`, `GGD_StationInfo_M.xlsx` ë“±)")
st.markdown("- ë§Œì•½ íŒŒì¼ ì¸ì½”ë”© ë¬¸ì œ(utf-8/cp949)ê°€ ìˆë‹¤ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
st.markdown("- ì¶”ê°€ì ìœ¼ë¡œ ì²˜ë¦¬í•´ë“œë¦´ ì‘ì—…(ì˜ˆ: ë²„ìŠ¤ ì •ë¥˜ì¥ ë°ì´í„° ì—…ë¡œë“œ/ì •êµí•œ ì‹œê°í™”)ì€ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì‹œë©´ ë°”ë¡œ í†µí•©í•´ ë“œë¦½ë‹ˆë‹¤.")
